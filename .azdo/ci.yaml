resources:
  containers:
    - container: mlops
      image: mcr.microsoft.com/mlops/python:latest

pr: none
trigger:
  branches:
    include:
      - master
  paths:
    include:
      - code/

variables:
  - group: kubefow-azdo-sample

pool:
  vmImage: ubuntu-latest

stages:
  - stage: "Code_Quality_Check"
    displayName: "Code Quality Check"
    jobs:
      - job: "Code_Quality_Check"
        displayName: "Code Quality Check"
        container: mlops
        timeoutInMinutes: 0
        steps:
          - task: Bash@3
            inputs:
              targetType: 'inline'
              script: 'echo "this is a placeholder to test the rest of the pipeline"'
          # - template: code-quality-template.yml

  # - stage: "Build_and_Push_Images"
  #   displayName: "Build and Push Images"
  #   jobs:
  #     - job:
  #       steps:
  #       - task: Docker@2
  #         inputs:
  #           containerRegistry: 'kubeflow-azdo-sample-acr-sc'
  #           repository: 'mexicanfood/databricks-notebook'
  #           command: 'buildAndPush'
  #           Dockerfile: '**/Dockerfile'
  #           buildContext: 'code/preprocess/'
  #           tags: 'latest'

  - stage: "Build_Kubeflow_Pipeline"
    displayName: 'Build Kubeflow Pipeline'
    variables:
    - group: kubeflow-task-variables
    jobs:
      - job: 
        steps:
        - task: UsePythonVersion@0
          inputs:
            versionSpec: '3.7'
            addToPath: true
            architecture: 'x64'
        - task: CmdLine@2
          inputs:
            script: |
              pip install kfp --upgrade
              cd code
              python pipeline.py
              dir

  # - stage: "Upload_Pipeline"
  #   displayName: "Upload Pipeline"
  #   variables:
  #   - group: kubeflow-task-variables
  #   jobs:
  #     - job:
        # steps:
        - task: Bash@3
          inputs:
            targetType: 'inline'
            script: |
              ls
              echo '------------------------------------------'
              cd code
              ls
        - task: KubeflowUploadPipeline@0
          inputs:
            kubeflowEndpoint: '$(kf_endpoint)'
            kubeflowPipelineTask: '$(kf_upload_choice)'
            pipelineFilePath: '$(kf_pipeline_file)'
            newPipelineName: '$(kf_new_pipeline_name)'
            existingPipelineName: '$(kf_existing_pipeline_name)'
            versionName: '$(kf_new_version_name)'
        - task: KubeflowExperimentRun@0
          inputs:
            kubeflowEndpoint: '$(kf_endpoint)'
            pipeline: '$(kf_new_pipeline_name)'
            pipelineVersion: '$(kf_existing_version_name)'
            runName: '$(kf_run_name)'
            pipelineParams: '$(kf_pipeline_params)'
            runDescription: '$(kf_run_description)'
            experiment: '$(kf_experiment_choice)'
            experimentName: '$(kf_experiment_name)'
          condition: 
            and(succeeded(), eq(variables['kf_upload_choice'], 'uploadNew'))

        - task: KubeflowExperimentRun@0
          inputs:
            kubeflowEndpoint: '$(kf_endpoint)'
            pipeline: '$(kf_existing_pipeline)'
            pipelineVersion: '$(kf_existing_version_name)'
            runName: '$(kf_run_name)'
            pipelineParams: '$(kf_pipeline_params)'
            runDescription: '$(kf_run_description)'
            experiment: '$(kf_experiment_choice)'
            experimentName: '$(kf_experiment_name)'
          condition: 
            and(succeeded(), eq(variables['kf_upload_choice'], 'uploadNewVersion'))